A conceptually simple mass balance method is used to estimate the daily Se loading to the river from the alluvium or unloading from the river to the alluvium.  Flow and water quality data is gathered from reliable sources and stochastically modeled based on the assumed accuracy of the data.  Some of this data is then used to estimate Se concentrations at various locations in the river.  The flow data and the estimated Se concentrations are used to calculate Se loading to the river and discharges from the river.

A large portion of this work is a continuation of \citet{Mueller2008}.  This work described in this thesis was funded by the same organizations and is intended to build upon their work.  When possible and appropriate, the methods employed by \citeauthor{Mueller2008} were used in the course of this investigation.  Efforts were also made to use similar nomenclature and symbology when possible.

The goal of \citeauthor{Mueller2008} was to estimate constituent loading to the Arkansas R. and to explore the uncertainty surrounding the estimate.  Their work focused on the same study regions as this work, but on two constituents, total dissolved solids and dissolved Se.  Sufficient data was gathered to analyze dissolved Se loading in only the downstream study reach (DSR) over twelve sample periods, encompassing 16 days.  They were able to determine that the mean daily Se load to the river per unit length was 0.038 \si{\kilo\gram\per\day\per\kilo\meter} with a coefficient of variation (CV) of 0.24.  The current study, as reported in this thesis, was able to calculate similar results.

A regional study performed by the US Geological Survey (USGS) \citep{Miller2010}, is the foundation of both the \citeauthor{Mueller2008} study and this one.  The USGS study found that dissolved Se concentrations and variability did not increase substantially between Avondale and Las Animas, that loads decreased between Avondale and Catlin, then remained constant to Coolidge.  There is a notable decrease in Se concentration in John Martin Reservoir that may be due to periodic chemical reductive processes that are currently unknown.  Concentrations below John Martin Reservoir double between the Reservoir and Coolidge.

Both this study and the \citeauthor{Mueller2008} study used the mass balance approach to estimate Se loading to the river.  The mass balance approach has been used for many different water quality constituents in many applications.  Using this method to estimate an unknown, spatially and temporally variable, yet immeasurable source, such as groundwater has not been done often.  Most examples found in literature sought the mass balance of a lake, pond, or other large water body \citep{Gersberg2006, Takayanagi1984}. Other than the study performed by \citeauthor{Mueller2008}, there is no known groundwater mass balance or loading analyses performed on a river reach.  A lack of a comparative model is probably due to the uniqueness of this system.  Most other mass balance studies performed on constituents that originate from non-point sources have some idea as to where and how the constituent is added to the water body.  While groundwater is a water source in these models, is usually not a source of, but a sink for, the contaminant.  In this study, the groundwater is suspected of being a primary contributor to Se loading in the Arkansas R.

\citeauthor{Mueller2008} did not perform a Se loading analysis in the USR, therefore the sampling locations used in that study are not pertinent in this discussion.  They did perform a Se loading analysis on the DSR.  They reported three canals in the DSR.  At the start of this study there were only two within the same study region boundaries.  Since much of the river in the DSR is unreachable by foot, a survey of the reach was performed by using satellite imagery provided through the National Agricultural Imagery Program (NAIP).  A possible location for a diversion structure was located, but the structure appeared to have been breached and the canal served by the structure had large diameter bushes or trees growing along its base.  We assumed that this diversion and its canal were no longer in use and it was not included in the current study.

Se volitalization, which has been estimated in the Great Salt Lake and constructed wetlands in the San Joaquine River Valley, has not been estimated for a river.  We believe that volitalization rates at these two locations cannot be applied to the Arkansas River due to the large differences in the water bodies or their locations.  The Great Salt lake is a highly saline lake with no discharge.  The San Joaquine River, while being a regional agricultural drain, is in a climate with average annual temperatures much higher than those in the LARB.  This temperature difference is a suspected contributor to the success of the irrigated wetlands.

This study followed the example set in \citet{Mueller2008} when determining the relationship between the flow depth and river water top width.  Both their study and the current study use this information and relationship to estimate the change in river storage volume between any two time periods.  The equation they used is well founded in the available literature \citep{Gates1996, Buhman2002}.  The only noticeable difference is that they used survey data provided by the US Geological Survey (USGS) while this study used an independent set of survey data to generate an average cross section geometry for each of the sub-reaches, or river segment, defined in each study reach.

The most noticeable is the collection and treatment of electrical conductivity, standardized at \ang{25}C (EC).  \citep{Mueller2008} used portable equipment, whereas this study used measurements from permanent, continuously monitoring equipment.  While both sets of equipment are essentially the same in design and operating principle, and receive the same maintenance and calibration, field technicians found that the portable equipment tended to have a noticeable calibration drift during a single sampling day.  A more stringent and frequent maintenance and calibration regiment was implemented for a short time.  The cause of the malfunction was not found or remedied and the additional labor time proved to be detrimental to the overall project goals.  Permanently deployed equipment did not appear to suffer the same calibration drift.  This is probably due to the method by which they are deployed.  The USGS owns and operates the majority of the river water quality monitoring equipment in Colorado.  They have standardized maintenance practices, and are capable of calculating an estimated EC value when calibration drifts do occur.

In using the field measured EC values, \citeauthor{Mueller2008} had to go through an extra step to determine an error parameter for the difference between the field measured value and the value provided by the permanently deployed equipment.  In using the data recorded by the permanently deployed gauges as the primary source of EC data, this study avoided that step, reducing calculation steps and overall error. 

They also used an error parameter to account for the spatial difference in EC values at a single cross section.  A separate sub-study to determine the suspended sediment concentration in the USR provided surprising secondary results that are contrary to those stated in \citeauthor{Mueller2008}, in which they stated that the CV for the EC deviation was 0.05 at any cross section.  The current study found that EC values did not change across any of the cross sections.  A noticeable change in EC was reported by the equipment during the first few minutes it was placed in the water, but afterwards did not deviate.  After discussions with equipment manufacturer representatives, it was determined that this initial change in reported value was due to the equipment not being in temperature equilibrium with the surrounding water.  If any deviation in EC was noted in the suspended sediment study, the CV for that deviation would be at least one order of magnitude lower than reported by \citeauthor{Mueller2008}.

Another error parameter was used by \citeauthor{Mueller2008} to account for the temporal change in EC values.  They had a single instrument, capturing data at a single point in time for any given day.  This then required that they determine an estimated or average EC value over the sampling time frame of between one and three days.  The current study in employing the existing, permanently deployed gauges, was able to ignore the temporal error.  It is acknowledged in the calculations, but that error is included in a combined error calculation.  The US Geological Survey has data quality qualifiers that signify to the data user the amount of error associated with a reported measurement.  This study was concerned with average daily measurements and as such it was expected that there would be an amount of error associated with the difference between the reported average daily value and the value reported at any single time.  We also expected errors associated with equipment calibration drift or other minor technical concerns.  The USGS combines these errors into a single value and reports the possible percent deviation from the reported value with the upper and lower limits of the reported deviation such that 95\% of the error is captured within its bounds.

\citeauthor{Mueller2008} used a single power function of the EC value to estimate dissolved Se concentrations at all points in the model.  These values were then compared to the Se grab sample results and an error distribution was created for each sampling location.  The calculation method they chose is probably indicative of the low quantity of available data for each sample location.  With the significant increase in sample quantity since that study was completed, this study was able to take a different approach.  The current study uses multi-variate linear functions of multiple, continuously monitored water quality and flow values to estimate dissolved concentration at various points.  The residuals from these estimating equations were used to generate one of the random error parameters.

The previous study assumed that Se was conservative.  While essentially true in that Se is not converted into another element, Se has multiple pathways within its fate transport, not all of which were represented in the loading equation.  Se can have four oxidation states (-II, 0, IV, and VI).  Elemental Se, with a oxidation state of 0 , is a solid only transportable by physical means.  Dissolved Se has two primary oxidation states.  The IV oxidation state is usually found as selenite compounds.  It is soluble, but not very mobile as it has an affinity for ad- and absorption.  The least desirable oxidation state, Se VI, is usually found as selenate compounds.  In this state, Se is highly soluble and has a very low affinity for ad- and absorption.  Once in this state, Se is rate limited toward reduction \citep{Oram2010}.

Se can also be volatilized, or vaporized to the atmosphere, through plant transpiration processes.  Multiple studies have been performed in various wetlands in California's San Joaquin valley to determine the rate of Se volatilization from the water surface and through plant evapo-transpiration processes.  The range of Se volatilization reported in these studies is 17-50\% of the original mass.  All of these studies used time frames that are more than double the water detention time of either the USR or the DSR under the slowest recorded flow velocities reported by the USGS.  There is no known and tested sliding scale or conversion methodology to convert the Se transfer in the San Joaquin valley to the Lower Arkansas River valley.  These studies were based in natural and constructed wetlands whereas the Arkansas R. is a naturally free flowing river.  There are relatively small sections where the flow velocity is low enough to encourage natural wetland development, but they are insignificant to the total river reach \citep{Gersberg2006, Gersberg2009}.

No previous studies of Se in rivers considers volitalization.  This is probably be due to the difficult nature of measuring and estimating a constantly moving water body.  A river is in a constant state of change where trying to make these measurements is difficult.

Soil and pore water chemistry also has a role in Se oxidation, ad- and absorption, and sequestration.  One study found that the soil and pore water chemistry was exceedingly complex and would present difficulties in accurately describing \citep{Oram2008}. Se speciation in sediments depends on multiple interacting biological, chemical, and physical processes that can release or sequester Se in sediment environments making predictions of Se mobility highly complex.  Direct uptake of Se by plants, insects, bottom dwelling organisms, and detritus-feeding fish and wildlife are important pathways that can affect the dynamics of Se bio-geochemical cycling in sediments.  Differences between sediment Se species are attributed to these complex sediment processes that are likely variable across the stream sediments.  In the case of the Blackfoot River in South Eastern Idaho, Se is sequestered in sediments in a non-mobile state.  It is not known if the processes identified by Oram are similar to the ones in the LARB.

\citeauthor{Mueller2008} used the coefficient of variation (CV) throughout their study.  CVs are standardized standard deviations which allow the comparison of distributions that have different value ranges.  To be accurately interpreted, CVs should only be calculated for value ranges where the smallest possible value is greater than zero and the mean value does not approach zero.  In this study, it was found that resulting loading values could be negative, indicating that Se was being discharged from the river channel into a sink.  This was not a random occurrence and happened on multiple consecutive days.  Therefore, CV values were not used as they would not accurately depict the relative deviation in the results.  This study uses the more traditional mean and standard deviation to describe a distribution.  When more descriptive statistics are required, the skewness and kurtosis are reported.

A sensitivity analysis was performed in the previous work by \citeauthor{Mueller2008}.  The analysis was based on 1/2 and 2 times the variation with sensitivity score taken as a function of CV values.  Since CV has been considered a non effective comparative parameter, we question the results of that sensitivity analysis.  It was not clear whether they knew that the results were not conducive to using CV.

The intent of any sensitivity analysis is to either eliminate or fix input variables and is an expected part of any statistical analysis \citep{Saltelli2004}.  The US Environmental Protection Agency (USEPA) has guidelines for and insists on the need for uncertainty and sensitivity analysis (1999).

None of the input variables used in this study can be removed without compromising the integrity of the model.  One or two variables may have a small contribution to the whole model, but their contribution is much more pronounced in the individual Se concentration estimating equations.  In the case of this study, the sensitivity analysis will be used to determine which variables have the largest impact on the final results.  This will give us an estimate as to the degree to which the uncertainty associated with each input parameter affects the model.  Those parameters that have a large affect on the model will induce a larger effect if their associated uncertainty is large.  The sensitivity analysis will not be performed on the stochastic model or run through the Monte Carlo simulation.  There is a concern that small, but realistic changes in an input variable may not produce noticeable changes in the simulation results.  Therefore, the sensitivity analysis will be performed on the deterministic model.  This model is constructed in the same manner as the stochastic model, but without any of the associated parameter uncertainty or estimation error terms.

\citeauthor{Mueller2008} and this study use Monte Carlo simulation to determine a series of likely realities.  Statistics are taken of these likely realities to determine a probable range for the simulation results.  Another simultation method, Markov Chain Monte Carlo (MCMC), was not used in either study.  MCMC relies on the state of the variables in the previous time step to estimate a parameter in the new time step.  Since variable states in this system are independent of the previous time step, otherwise known as memoryless, MCMC is not used.

\citet{Spanou2001} has performed a similar study using an object-oriented framework to predict multiple water quality constituents.  As with \citet{Mueller2008}, the data size is small compared to the data set used for this study.  Spanou's model works in a similar manner to the models developed in this study.  Part of his focus was to develop a software package that could be used for various scenarios and locations.  The purpose of this study was much more focused.  We only need to provide results for a single constituent over a specified, but large, time frame.  Once results are obtained, the likelihood that the model developed in this study will ever be run again is uncertain.




UNUSED WATER BALANCE TEXT

%If we assume that all flows moving into or out of the river reach are known or can be reasonably well estimated, then the volume of water being stored during any time step is the sum of the flows being added to the river reach minus the flows being removed from the river reach.  This model accounts for flows moving through two cross sections of the river reach, the contributions from tributaries and precipitation or contributions to irrigation canals and evapo-transpiration (ET).  It also accounts for measured, known point sources.  It does not account for unknown and unmeasured surface water flows, or the flux of water between the river channel and the riparian aquifer.  The complete water balance equation form used for both study reaches was developed by expanding the basic water balance equation (\ref{eq:qbalbasic}) to include all known, measurable values.

%\begin{equation}
%	\frac{\Delta S}{\Delta t}=\sum{Q_{inflow}}-\sum{Q_{outflow}}+P-E+\sum{Q_{NPS}}
%	\label{eq:qbalbasic}
%\end{equation}
%\begin{tabular}{rl}
%$\frac{\Delta S}{\Delta t}$ =&Stored volume change between time steps $(volume \cdot time^{-1})$\\
%$\sum{Q_{inflow}}$=&Sum of measured flows entering the river section $(volume \cdot time^{-1})$\\
%$\sum{Q_{outflow}}$=&Sum of measured flows leaving the river section $(volume \cdot time^{-1})$\\
%$P$=&Precipitation in units of $volume \cdot time^{-1}$\\
%$E$=&Evaporation in units of $volume \cdot time^{-1}$\\
%$\sum{Q_{NPS}}$=&Sum of all flow rates to or from non-point sources $(volume \cdot time^{-1})$\\
%\end{tabular}\\

%The variable $\sum{Q_{UNPS}}$ is intended to capture all of the gains from and losses to the unaccounted for non-point sources and sinks and the riparian aquifer.  It is assumed that the unaccounted for non-point sources and sinks are relatively minor and intermittent.  They can include, but are not limited to, surface runoff from storm events, irrigation water returning directly from fields to the river, and groundwater.  Flows from the sum of the non-point sources $(Q_{UNPS})$ can be either added to or taken from the river reach.  The equation assumes that these flows are added to the river.  As such, positive values indicate that the river is gaining water from non-point sources and negative values indicate the river is losing water to non-point sinks.  For this study, we are assuming that the non-point source flows are dominated by groundwater interactions with the river channel.  Changing the unknown flow variable to only consider groundwater, rearranging the flow equation variables results in equation~\ref{eq:qbalbasic2}.

%\begin{equation}
%	Q_{GW}=\frac{\Delta S}{\Delta t}-\sum{Q_{inflow}}+\sum{Q_{outflow}}-P+E
%	\label{eq:qbalbasic2}
%\end{equation}
%
%Groundwater flows are not shown as a sum of flows like the measured inflow and outflows.  Considering them as a sum value implies that there is a way to separate them in some manner.  Groundwater contributions to the flow equation, either gains or losses, are variable along any river segment.  Grouping the variables by type produces equation~\ref{eq:qbalbasic3}, which is used as the final step of the computations.  All computations prior to this assume all storage changes, flows, precipitation, and evaporation are positive.  This step was used to help with book keeping.
%
%\begin{equation}
%	Q_{GW}=\frac{\Delta S}{\Delta t}-Q_{Surface}-Q_{Atmosphere}
%	\label{eq:qbalbasic3}
%\end{equation}
%Where\\
%\begin{tabular}{rl}
%$Q_{Surface} =$& $\sum{Q_{inflow}} - \sum{Q_{outflow}}$ Cumulative water flow rate.\\
%$Q_{Atmosphere} =$&$P-E$ Cumulative effects of precipitation and evaporation.\\
%\end{tabular}\\
%
%
%
%The eight computational models presented in the preceding list have one characteristic in common; all eight are time series models.  The reference time frames are identical for all eight models.  The time frame spans from 1 October 2006 to 30 September 2010.  The start and end dates are concurrent with the start of the 2007 water year and the end of the 2010 water year as defined by the USGS, respectively \parencite{USGS2014}.
%
%Since most of the data was readily available in average daily form, it seemed reasonable to set the time step within the time frame equal to one day.  The added benefit is that the results could be used to help calibrate MODFLOW and RT3D models developed under the same project for the same study regions as described in this thesis.
%
%Not all time steps with the time frame were found to be suitable for analysis.  A time step was deemed suitable only if all of the data points required for the respective selenium mass balance deterministic model were available.  It was determined that attempting to calculate with any number of missing data points or attempting to estimate the missing data points for a given time step would add additional immeasurable uncertainty to the results.  The number of required variables is 23 for the USR and 14 for the DSR.  For the USR, 1,085 of 1,461 days, or approximately 74\%, were found to be suitable for inclusion in the analysis.  For the DSR, 838 days, or approximately 57\% were found to be suitable.




Stoch and Determ models

This model was run for 10,000 itterations

.  The first model was created such that solutions for individual realizations were calculated individually.  This model's computational form was extremely slow in producing fairly acceptable results.  It took approximately 2.5 days to calculate a little over 7,500 realizations with only five of the six monitored statistics reaching the desired point.  For some reason, the final change in skewness between successive groups of realizations was 3-5\% based on five model runs.  A second model was created such that the solutions were calculated in a batch format using matrix math.  Many sources with extensive and diverse computer code development knowledge stated that matrix math operations complete computations many orders of magnitude faster than the one calculation at a time method used in the first model.  This proved to be true as a 5,000 realization model was completed in just under 2.25 hours.

One run was of the second stochastic model form was performed at 500 realizations to determine the minimum number of required realizations.  The mean, 2.5th and 97.5th percentile, variance, skewness, and kurtosis were the monitored statistics.  The statistics were considered acceptable when the change between calculations of the 1 to $r$ realization and the 1 to $r-1$ realization was less than 0.1\%.  It was found that these variables were acceptable or nearly acceptable shortly before the 500th realization.  A large factor of safety was added to this and 5000 realizations were performed.

Deterministic models used the reported values from the input variables.  In all cases, the reported values were considered the expected values.  Therefore, the terms deterministic model value, reported value, and expected value were used interchangeably in this study as they all refer to the same values.  Stochastic model input variables were defined from distributions of the reported values.  They were generated as $t$ rows by $r$ columns matrices where $t$ was the number of time steps in the study time frame and $r$ was the number of realizations.

The stochastic models were derived from the deterministic models with the addition of error terms.  The stochastic model was then converted into a computational stochastic model.  This models was debugged and validated by testing the random error distributions and comparing the final results to previous studies.  The computational deterministic models were then derived from the computational stochastic models by removing all of the error distributions from the computational code.  The deterministic models were then compared to the original spreadsheet models.